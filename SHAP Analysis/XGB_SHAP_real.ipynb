{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa49fc4",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cb7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv(\"df_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98404c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_variables = np.array([\n",
    "    'Emissions|CO2', \n",
    "    'Final Energy|Industry|Solids|Coal', \n",
    "    'Final Energy|Industry|Solids|Biomass',\n",
    "    'Final Energy|Residential and Commercial|Solids|Coal', \n",
    "    'Emissions|CO2|Energy|Demand|Industry',\n",
    "    'Secondary Energy|Electricity|Coal', \n",
    "    'Emissions|CO2|Energy|Supply|Electricity',\n",
    "    'Primary Energy|Coal', \n",
    "    'Emissions|CO2|Energy and Industrial Processes', \n",
    "    'Emissions|CO2|AFOLU'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ceed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_vars_set = set(shap_variables)\n",
    "num_shap_vars = len(shap_vars_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_target.groupby(['Model', 'Scenario'])\n",
    "pair_counts = df_grouped['Variable'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa50868",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_pairs_index = []\n",
    "for index, group in df_grouped:\n",
    "    variables_in_pair = set(group['Variable'])\n",
    "    if variables_in_pair >= shap_vars_set:  \n",
    "        common_pairs_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if common_pairs_index:\n",
    "    df_shap = df_target[df_target.set_index(['Model', 'Scenario']).index.isin(common_pairs_index)]\n",
    "else:\n",
    "    df_shap = pd.DataFrame(columns=df_target.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a417ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if common_pairs_index:\n",
    "    df_temp = df_target[df_target.set_index(['Model', 'Scenario']).index.isin(common_pairs_index)]\n",
    "    df_shap = df_temp[df_temp['Variable'].isin(shap_variables)]\n",
    "else:\n",
    "    df_shap = pd.DataFrame(columns=df_target.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f154d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_pairs_index = pd.MultiIndex.from_tuples(common_pairs_index, names=['Model', 'Scenario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap.to_csv(\"df_shap.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paired = df_shap.set_index(['Model', 'Scenario', 'Variable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd220f",
   "metadata": {},
   "source": [
    "## Constrcy feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_cols = [col for col in df_shap if col.isdigit()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e49089",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_vars = [\n",
    "        'Emissions|CO2', 'Final Energy|Industry|Solids|Coal',  'Final Energy|Industry|Solids|Biomass', \n",
    "        'Final Energy|Residential and Commercial|Solids|Coal', 'Emissions|CO2|Energy|Demand|Industry', \n",
    "        'Secondary Energy|Electricity|Coal', 'Emissions|CO2|Energy|Supply|Electricity', \n",
    "        'Primary Energy|Coal','Emissions|CO2|Energy and Industrial Processes', 'Emissions|CO2|AFOLU'\n",
    "        ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ea508",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_features_list = []\n",
    "\n",
    "for var in shap_vars:  \n",
    "    print(f\"Process Variable '{var}'...\")  \n",
    "    var_idx = pd.MultiIndex.from_product([common_pairs_index.get_level_values('Model'),  \n",
    "                                                     common_pairs_index.get_level_values('Scenario'),  \n",
    "                                                     [var]], names=['Model', 'Scenario', 'Variable'])  \n",
    "\n",
    "    valid_var_idx = var_idx.intersection(df_paired.index)  \n",
    "    if valid_var_idx.empty:  \n",
    "        print(f\"Warning: Variable '{var}' is not in the DataFrame index. Skipping...\")  \n",
    "        continue  \n",
    "\n",
    "    var_data = df_paired.loc[valid_var_idx, year_cols]  \n",
    "    var_data = var_data.reset_index(level='Variable', drop=True)  \n",
    "    var_data = var_data.apply(pd.to_numeric, errors='coerce')  \n",
    "    \n",
    "    if not year_cols:\n",
    "        feature1 = pd.Series(0.0, index=var_data.index) \n",
    "        print(f\"Warning: Variable '{var}' has no year columns in range 2020-2100. Feature 1 (Sum) set to 0.\")  \n",
    "    else:  \n",
    "        feature1 = var_data[year_cols].sum(axis=1, skipna=True)  \n",
    "        feature1.name = f\"{var} Cumulative\"  \n",
    "\n",
    "    if '2020' in var_data.columns and '2030' in var_data.columns:  \n",
    "        feature2 = (var_data['2030'].fillna(0) - var_data['2020'].fillna(0)) / 10  \n",
    "    else:  \n",
    "        print(f\"    Warning: Variable '{var}' missing '2020' or '2030' data, Feature 2 set to NaN.\")  \n",
    "        feature2 = pd.Series(np.nan, index=var_data.index) \n",
    "    feature2.name = f\"{var} 2020-2030\"  \n",
    "\n",
    "    if '2040' in var_data.columns and '2050' in var_data.columns:  \n",
    "        feature3 = (var_data['2040'].fillna(0) - var_data['2030'].fillna(0)) / 10  \n",
    "    else:  \n",
    "        print(f\"    Warning: Variable '{var}' missing '2030' or '2040' data, Feature 3 set to NaN.\")  \n",
    "        feature3 = pd.Series(np.nan, index=var_data.index) \n",
    "    feature3.name = f\"{var} 2030-2040\" \n",
    "\n",
    "\n",
    "    var_features_df = pd.concat([feature1, feature2, feature3], axis=1)  \n",
    "    all_new_features_list.append(var_features_df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91219cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat(all_new_features_list, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdffc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_map = df_shap.groupby(['Model', 'Scenario'])['PC_m'].first()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac435777",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = xy_map.loc[X.index]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85994f2b",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d6f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144134c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f26ff7",
   "metadata": {},
   "source": [
    "## Fitting XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa778ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "parameters = {\n",
    "    'n_estimators': [100, 200, 400, 800],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'min_child_weight': [ 3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Starting GridSearchCV for hyperparameter tuning...\")\n",
    "gridsearch = GridSearchCV(classifier, parameters, cv=cv_strategy, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_params = gridsearch.best_params_\n",
    "xgb_best_estimator = gridsearch.best_estimator_\n",
    "\n",
    "print(f\"\\nBest Parameters Found by GridSearchCV: {gridsearch.best_params_}\")\n",
    "print(f\"Best cross-validated accuracy score during GridSearchCV: {gridsearch.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(xgb_best_estimator, X, y, cv=cv_strategy, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"\\nCross-Validation Accuracy Scores for each fold: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation of Cross-Validation Accuracy: {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassifier(**gridsearch.best_params_, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_classifier.fit(X, y)\n",
    "print(\"Final model trained successfully on all data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = xgb_classifier.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importance})\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86890177",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  \n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde81b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb_classifier)  \n",
    "shap_output = explainer(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41076e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(shap_output, shap.Explanation):\n",
    "    raw_vals = shap_output.values\n",
    "else:\n",
    "    raw_vals = shap_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244dba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(raw_vals, np.ndarray) and raw_vals.ndim == 3:\n",
    "    shap_values = [ raw_vals[:, :, i] for i in range(raw_vals.shape[2]) ]\n",
    "else:\n",
    "    shap_values = raw_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 12,\n",
    "    \"figure.dpi\": 120,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 4,\n",
    "    \"ytick.labelsize\": 2\n",
    "})\n",
    "plt.rcParams['font.family'] = ['Microsoft YaHei']      \n",
    "plt.rcParams['axes.unicode_minus'] = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'Emissions|CO2',\n",
    "    'Final Energy|Industry|Solids|Coal',\n",
    "    'Final Energy|Industry|Solids|Biomass',\n",
    "    'Final Energy|Residential and Commercial|Solids|Coal',\n",
    "    'Emissions|CO2|Energy|Demand|Industry',\n",
    "    'Secondary Energy|Electricity|Coal',\n",
    "    'Emissions|CO2|Energy|Supply|Electricity',\n",
    "    'Primary Energy|Coal',\n",
    "    'Emissions|CO2|Energy and Industrial Processes',\n",
    "    'Emissions|CO2|AFOLU'\n",
    "]\n",
    "\n",
    "palette_var = sns.color_palette(\"tab10\", len(variables))\n",
    "color_map = {v: palette_var[i] for i, v in enumerate(variables)}\n",
    "color_map['Sum of the rest'] = (1.0, 0.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28665a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 15  \n",
    "feature_names = X.columns.to_list()\n",
    "class_names = ['P1','P2','P3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 10,\n",
    "    \"figure.dpi\": 120,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 8\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c733390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_yticks(ax):\n",
    "    for lbl in ax.get_yticklabels():\n",
    "        txt = lbl.get_text()\n",
    "        if txt == 'Sum of the rest':\n",
    "            lbl.set_color(color_map['Sum of the rest'])\n",
    "        else:\n",
    "            var = txt.split('_')[0]\n",
    "            lbl.set_color(color_map.get(var, 'black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6032ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, cls in enumerate(class_names):\n",
    "    sv        = shap_values[idx]              \n",
    "    abs_mean  = np.abs(sv).mean(axis=0)      \n",
    "    order     = np.argsort(abs_mean)[::-1]\n",
    "    top_idx   = order[:top_k]\n",
    "    rest_idx  = order[top_k:]\n",
    "\n",
    "    cols      = [feature_names[i] for i in top_idx] + ['Sum of the rest']\n",
    "    shap_mat  = np.concatenate([\n",
    "        sv[:, top_idx],\n",
    "        np.abs(sv[:, rest_idx]).sum(axis=1, keepdims=True)\n",
    "    ], axis=1)\n",
    "    X_mat     = np.concatenate([\n",
    "        X.iloc[:, top_idx].values,\n",
    "        np.abs(sv[:, rest_idx]).sum(axis=1, keepdims=True)\n",
    "    ], axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10/1.46,10))\n",
    "    shap.summary_plot(\n",
    "        shap_mat, X_mat,\n",
    "        feature_names=cols,\n",
    "        plot_type=\"violin\",\n",
    "        sort=False,        \n",
    "        show=False\n",
    "    )\n",
    "    ax = plt.gca()\n",
    "    plt.gca().tick_params(axis='y', labelsize = 8)\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    color_yticks(ax)   \n",
    "    ax.set_xlabel(\n",
    "    \"SHAP value (impact on model output)\",\n",
    "    fontsize=12,\n",
    "    fontweight='bold',\n",
    "    labelpad=15\n",
    "    )\n",
    "    for text in ax.texts:\n",
    "        if text.get_text() == 'Feature Value':\n",
    "            text.set_fontweight('bold')\n",
    "    plt.savefig(f\"SHAP of Synthetic {cls}.png\", dpi=600, bbox_inches = 'tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
